{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victor Castellanos\n",
    "### Ian Schenck\n",
    "### CECS 550 Project 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set User Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is initial k\n",
    "k = 4\n",
    "# T is number of groups for cross validation\n",
    "T = 5\n",
    "# R1 is start of range for optimizing k\n",
    "R1 = 1\n",
    "# R2 is end of range for optimizing k\n",
    "R2 = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a file that uses , as delimiter\n",
    "def load_file(path, names):\n",
    "    if not path.is_file():\n",
    "        raise FileNotFoundError(str(path))\n",
    "    data = pd.read_csv(path, sep=\",\", names=names, header=None)\n",
    "    return data\n",
    "\n",
    "# load data for hmm\n",
    "def load_df():\n",
    "    cols = [\"Fixed Acidity\", \"Volatile Acidity\",\"Citric Acid\", \"Residual Sugar\", \"Chlorides\", \"Free Sulfur Dioxide\", \"Total Sulfur Dioxide\", \"Density\",\"pH\", \"Sulphates\", \"Alcohol\" , \"Quality\"]\n",
    "    file = Path.cwd() / \"wine_quality.csv\"\n",
    "    return load_file(file, cols)\n",
    "\n",
    "# removes any rows that have empty data slots ie null\n",
    "def remove_empty_rows(data):\n",
    "    data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=True)\n",
    "    return data\n",
    "\n",
    "# removes outliers based on zscore greater than 3\n",
    "def remove_outliers_Zscore(data):\n",
    "    z = np.abs(stats.zscore(data))\n",
    "    data_df_z_out =data[(z<3).all(axis=1)]\n",
    "    return data_df_z_out\n",
    "\n",
    "# removes outliers based on IQR\n",
    "def remove_outliers_IQR(data):\n",
    "    Q1 = data.quantile(.25)\n",
    "    Q3 = data.quantile(.75)\n",
    "    IQR = Q3-Q1\n",
    "    data_df_IQR_out = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "    return data_df_IQR_out\n",
    "    \n",
    "# graphs histogram\n",
    "def plotHistogram(data):\n",
    "    data.hist(bins=50, color='steelblue', edgecolor='black', linewidth=1.0,\n",
    "        xlabelsize=8, ylabelsize=8, grid=False)    \n",
    "    return plt.tight_layout(rect=(0, 0, 1.2, 1.2)) \n",
    "\n",
    "# makes a 2d graph comparing all pairs of features in dataframe\n",
    "def plot2dScatter(data):\n",
    "    return sns.pairplot(data,diag_kind=\"kde\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datasize before cleaning 4901\n",
      "Number of classes before cleaning data 9\n",
      "Removing outliers using z-score\n",
      "Current data size after removing outliers 4558\n",
      "Number of classes after cleaning data 5\n"
     ]
    }
   ],
   "source": [
    "#uncomment to see histogram of data\n",
    "#hist = plotHistogram(data)\n",
    "print(\"Current datasize before cleaning\" , data.shape[0])\n",
    "data = remove_empty_rows(data)\n",
    "\n",
    "\n",
    "#uncomment to see data b4 cleaning in 2d graph\n",
    "#plot2d = plot2dScatter(data)\n",
    "classes = data.groupby('Quality')\n",
    "print(\"Number of classes before cleaning data\" , classes.sum().shape[0])\n",
    "\n",
    "\n",
    "print(\"Removing outliers using z-score\")\n",
    "\n",
    "#data = remove_outliers_IQR(data)\n",
    "data = remove_outliers_Zscore(data)\n",
    "print(\"Current data size after removing outliers\", data.shape[0])\n",
    "\n",
    "#Uncomment this to look at 2d plot of cleaned data\n",
    "#plot2d = plot2dScatter(data)\n",
    "\n",
    "classes = data.groupby('Quality')\n",
    "print(\"Number of classes after cleaning data\", classes.count().shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building and training the kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(columns=[\"Quality\"])\n",
    "y = data[\"Quality\"]\n",
    "\n",
    "# split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# scale data\n",
    "standard_scaler = StandardScaler()\n",
    "X_train = standard_scaler.fit_transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# change this to try different k\n",
    "k = 4\n",
    "\n",
    "# make model and fit data\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Testing kNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6., 6., 6., 7., 6., 4., 6., 7., 7., 6., 5., 7., 5., 5., 5., 6.,\n",
       "       5., 5., 5., 7., 5., 5., 6., 6., 5., 5., 6., 6., 4., 6., 5., 5., 6.,\n",
       "       6., 6., 5., 6., 7., 5., 6., 6., 5., 5., 6., 5., 6., 5., 5., 6., 5.,\n",
       "       5., 6., 6., 6., 6., 6., 5., 6., 5., 5., 6., 6., 5., 5., 7., 6., 6.,\n",
       "       5., 6., 7., 6., 6., 6., 5., 6., 7., 7., 4., 6., 7., 5., 5., 6., 7.,\n",
       "       6., 6., 6., 7., 6., 7., 5., 5., 5., 6., 6., 6., 6., 7., 7., 5., 6.,\n",
       "       6., 5., 6., 5., 5., 6., 6., 8., 6., 6., 6., 5., 6., 6., 5., 5., 6.,\n",
       "       6., 6., 4., 7., 5., 6., 5., 5., 6., 5., 6., 5., 6., 6., 6., 7., 7.,\n",
       "       4., 5., 8., 6., 6., 5., 6., 7., 6., 5., 6., 5., 5., 5., 5., 6., 6.,\n",
       "       5., 5., 5., 8., 8., 6., 6., 5., 5., 6., 8., 4., 5., 5., 5., 6., 6.,\n",
       "       6., 6., 5., 6., 6., 5., 6., 5., 7., 6., 6., 5., 5., 6., 5., 6., 6.,\n",
       "       7., 5., 6., 6., 5., 4., 4., 6., 6., 5., 5., 6., 5., 6., 6., 5., 5.,\n",
       "       5., 6., 6., 6., 5., 6., 6., 6., 5., 7., 5., 6., 6., 5., 7., 6., 6.,\n",
       "       6., 5., 5., 7., 7., 6., 6., 6., 6., 5., 5., 5., 8., 7., 6., 5., 6.,\n",
       "       6., 6., 6., 6., 5., 7., 7., 6., 5., 6., 6., 6., 4., 5., 5., 5., 5.,\n",
       "       5., 6., 5., 6., 6., 6., 4., 6., 6., 5., 6., 5., 5., 5., 7., 7., 6.,\n",
       "       5., 6., 5., 7., 6., 8., 8., 5., 6., 6., 6., 5., 5., 6., 6., 5., 5.,\n",
       "       6., 6., 6., 5., 6., 5., 7., 7., 6., 6., 6., 5., 7., 8., 5., 6., 6.,\n",
       "       6., 5., 6., 6., 7., 5., 5., 5., 5., 6., 8., 6., 4., 6., 7., 7., 6.,\n",
       "       5., 6., 6., 5., 6., 5., 7., 5., 6., 6., 6., 7., 6., 5., 6., 7., 6.,\n",
       "       5., 5., 6., 5., 6., 6., 6., 6., 7., 7., 7., 6., 5., 6., 6., 6., 6.,\n",
       "       6., 5., 5., 6., 5., 5., 7., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "       5., 5., 5., 5., 6., 5., 6., 6., 5., 6., 4., 7., 7., 5., 5., 5., 6.,\n",
       "       7., 6., 6., 6., 7., 6., 6., 6., 7., 5., 7., 6., 5., 6., 5., 6., 6.,\n",
       "       6., 5., 5., 5., 4., 6., 7., 6., 6., 6., 6., 7., 5., 6., 6., 6., 5.,\n",
       "       6., 7., 5., 5., 5., 6., 5., 6., 5., 8., 5., 6., 6., 5., 5., 5., 5.,\n",
       "       5., 4., 5., 7., 5., 5., 5., 7., 6., 5., 5., 5., 6., 6., 5., 6., 5.,\n",
       "       6., 6., 6., 5., 7., 6., 6., 4., 6., 7., 5., 6., 5., 5., 6., 5., 5.,\n",
       "       5., 5., 5., 6., 6., 6., 6., 5., 6., 5., 6., 6., 5., 6., 7., 5., 5.,\n",
       "       7., 7., 5., 5., 6., 5., 5., 5., 6., 6., 6., 5., 5., 6., 5., 8., 5.,\n",
       "       6., 5., 5., 6., 6., 5., 5., 6., 5., 5., 6., 6., 7., 5., 6., 6., 5.,\n",
       "       8., 6., 6., 5., 6., 6., 6., 7., 5., 6., 5., 7., 5., 6., 6., 6., 5.,\n",
       "       5., 6., 6., 6., 4., 6., 5., 6., 7., 4., 6., 6., 5., 6., 6., 7., 6.,\n",
       "       4., 7., 6., 6., 6., 6., 6., 6., 4., 5., 5., 6., 5., 5., 5., 6., 6.,\n",
       "       5., 5., 6., 5., 6., 6., 5., 6., 7., 6., 7., 6., 5., 6., 7., 7., 7.,\n",
       "       7., 5., 6., 7., 6., 5., 5., 5., 7., 6., 5., 5., 6., 5., 4., 5., 5.,\n",
       "       6., 7., 5., 5., 5., 5., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
       "       6., 5., 4., 6., 5., 6., 6., 6., 5., 7., 5., 5., 6., 7., 6., 5., 6.,\n",
       "       6., 7., 5., 5., 5., 6., 6., 6., 7., 6., 5., 7., 5., 5., 5., 6., 5.,\n",
       "       5., 6., 7., 6., 7., 5., 7., 7., 4., 6., 6., 5., 6., 5., 5., 6., 6.,\n",
       "       5., 8., 6., 7., 6., 5., 6., 6., 5., 6., 6., 6., 5., 5., 5., 6., 6.,\n",
       "       5., 5., 5., 6., 6., 7., 5., 5., 6., 5., 5., 7., 5., 5., 6., 5., 7.,\n",
       "       6., 5., 4., 6., 4., 8., 5., 6., 6., 5., 6., 6., 6., 6., 7., 7., 6.,\n",
       "       7., 5., 6., 6., 6., 6., 6., 5., 5., 6., 6., 6., 5., 7., 5., 5., 6.,\n",
       "       6., 5., 5., 5., 6., 5., 6., 6., 5., 5., 7., 7., 6., 6., 5., 6., 5.,\n",
       "       5., 6., 6., 5., 6., 6., 6., 7., 7., 7., 6., 6., 6., 7., 5., 6., 6.,\n",
       "       6., 6., 5., 5., 5., 5., 6., 7., 6., 5., 6., 5., 6., 5., 6., 7., 5.,\n",
       "       5., 6., 5., 6., 6., 5., 7., 6., 8., 6., 5., 5., 5., 6., 5., 5., 5.,\n",
       "       6., 7., 5., 5., 8., 7., 6., 5., 7., 5., 6., 6., 8., 5., 5., 7., 6.,\n",
       "       7., 7., 4., 5., 5., 6., 6., 6., 5., 6., 5., 6., 5., 6., 7., 5., 6.,\n",
       "       6., 5., 7., 5., 5., 5., 5., 6., 5., 5., 5., 6., 7., 7., 6., 5., 8.,\n",
       "       5., 7., 5., 5., 5., 5., 6., 6., 6., 6., 6., 7., 5., 6., 6., 7., 5.,\n",
       "       7., 6., 5., 6., 6., 6., 6., 6., 6., 7., 6., 6., 5., 6., 6., 6., 6.,\n",
       "       6., 6., 6., 6., 6., 4., 6., 6., 6., 5., 5.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7246297312122875\n",
      "Test score: 0.555921052631579\n"
     ]
    }
   ],
   "source": [
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print(f\"Train score: {train_score}\")\n",
    "print(f\"Test score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.53561644 0.56104252 0.54595336 0.53909465 0.55006859]\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(model, X_train, y_train, cv=T)\n",
    "print(f\"Cross Validation Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Optimizing n-neighbor parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Best Score: 0.6058694459681843\n",
      "Grid Search Best K: 1\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'n_neighbors': np.arange(R1,R2,1),\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, cv = 5, n_jobs=-1)\n",
    "\n",
    "gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "best_score = gs_results.best_score_\n",
    "best_k = gs_results.best_params_['n_neighbors']\n",
    "print(f\"Grid Search Best Score: {best_score}\")\n",
    "print(f\"Grid Search Best K: {best_k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
